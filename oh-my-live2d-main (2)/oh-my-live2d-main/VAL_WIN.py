import torch
from CAM_S import CAMPPlus
from torch.utils.data import DataLoader, Dataset
import os
import numpy as np
import pandas as pd
from pathlib import Path

# å®šä¹‰è¶…å‚æ•°
data_dir = r"D:\æ¯”èµ›è§†é¢‘Videos\sopran_cutted"
val_batch_size = 16
num_workers = 0  # åœ¨Windowsä¸Šè®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
num_classes = 50
pretrained_weights = "MODEL_WEIGHT/logs_ddnet_sopran/2025-08-28_17-36-59/best_model.pth"
output_dir = r"D:\æ¯”èµ›è§†é¢‘Videos\sopranres"

# åˆ›å»ºä¿å­˜ç›®å½•
os.makedirs(output_dir, exist_ok=True)


class CustomDataset(Dataset):
    def __init__(self, data_dir, transforms=None):
        self.data_dir = Path(data_dir)
        self.MFCC_data_dir = self.data_dir / 'MFCC_Output'

        # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–‡ä»¶æŸ¥æ‰¾æ–¹å¼
        self.mfcc_files = list(self.MFCC_data_dir.glob('*_MFCC.xlsx'))
        self.transforms = transforms

        print(f"Found {len(self.mfcc_files)} MFCC files for inference")

        # é¢„åŠ è½½æ–‡ä»¶åæ˜ å°„ï¼Œé¿å…é‡å¤å¤„ç†
        self.sample_ids = [f.stem.replace('_MFCC', '') for f in self.mfcc_files]

    def __len__(self):
        return len(self.mfcc_files)

    def __getitem__(self, idx):
        mfcc_file = self.mfcc_files[idx]
        sample_id = self.sample_ids[idx]

        try:
            # ä½¿ç”¨æ›´é«˜æ•ˆçš„pandasè¯»å–æ–¹å¼
            MFCC_data = pd.read_excel(mfcc_file, header=None, engine="openpyxl").values
            MFCC_tensor = torch.tensor(MFCC_data, dtype=torch.float32).unsqueeze(0)

            if self.transforms is not None:
                MFCC_tensor = self.transforms(MFCC_tensor)

            return MFCC_tensor, sample_id

        except Exception as e:
            print(f"Error loading {mfcc_file}: {e}")
            # è¿”å›ç©ºæ•°æ®æˆ–è·³è¿‡
            return torch.zeros((1, 13, 100)), sample_id  # å‡è®¾MFCCç»´åº¦


def load_model(checkpoint_path, num_classes, device):
    """åŠ è½½æ¨¡å‹çš„ç‹¬ç«‹å‡½æ•°"""
    model = CAMPPlus(
        num_class=num_classes,
        input_size=1,
        embd_dim=8192,
        growth_rate=64,
        bn_size=4,
        init_channels=128,
        config_str='batchnorm-relu'
    ).to(device)

    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"Pretrained weights not found at {checkpoint_path}")

    # æ›´å¥å£®çš„æƒé‡åŠ è½½
    checkpoint = torch.load(checkpoint_path, map_location=device)

    if isinstance(checkpoint, dict):
        if 'state_dict' in checkpoint:
            model.load_state_dict(checkpoint['state_dict'])
        elif 'model' in checkpoint:
            model.load_state_dict(checkpoint['model'])
        else:
            model.load_state_dict(checkpoint)
    else:
        model.load_state_dict(checkpoint)

    print(f"âœ… Loaded pretrained weights from {checkpoint_path}")
    return model


def save_predictions_to_excel(net, val_loader, device, output_path):
    """ä¿å­˜é¢„æµ‹ç»“æœåˆ°Excelæ–‡ä»¶"""
    net.eval()
    all_preds = []
    all_filenames = []

    # æŠ€å·§åç§°åˆ—è¡¨
    tech_names = ["vibrato", "throat", "position", "open", "clean",
                  "resonate", "unify", "falsetto", "chset", "nasal"]

    with torch.no_grad():
        for batch_idx, (im, sample_ids) in enumerate(val_loader):
            im = im.to(device)

            try:
                # æ·»åŠ æ¨¡å‹æ¨ç†çš„å¼‚å¸¸å¤„ç†
                output, _, _ = net(im)
                output = output.view(output.shape[0], 5, 10)  # (B, 5, 10)
                preds = output.argmax(dim=1).cpu().numpy() + 1  # è½¬ä¸º 1-5

                all_preds.append(preds)
                all_filenames.extend(sample_ids)

                # è¿›åº¦æ˜¾ç¤º
                print(f"Processed batch {batch_idx + 1}/{len(val_loader)} - {len(sample_ids)} samples")

            except Exception as e:
                print(f"Error in batch {batch_idx}: {e}")
                continue

    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„æµ‹ç»“æœ
    if not all_preds:
        print("âš ï¸ æ²¡æœ‰è·å–åˆ°é¢„æµ‹æ•°æ®")
        return

    # åˆå¹¶æ‰€æœ‰batchçš„é¢„æµ‹ç»“æœ
    all_preds = np.concatenate(all_preds, axis=0)

    # åˆ›å»ºDataFrame
    df_results = pd.DataFrame({
        "Filename": all_filenames
    })

    # æ·»åŠ æ¯ä¸ªæŠ€å·§çš„é¢„æµ‹ç»“æœ
    for i, tech_name in enumerate(tech_names):
        df_results[tech_name] = all_preds[:, i]

    # æŒ‰æ–‡ä»¶åæ’åºå¹¶ä¿å­˜
    df_results = df_results.sort_values(by="Filename")
    df_results.to_excel(output_path, index=False)

    print(f"âœ… æ¨ç†å®Œæˆï¼å…±å¤„ç† {len(df_results)} ä¸ªæ ·æœ¬")
    print(f"âœ… ç»“æœå·²ä¿å­˜è‡³ï¼š{output_path}")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š é¢„æµ‹ç»“æœç»Ÿè®¡ï¼š")
    for tech in tech_names:
        print(f"{tech}: å‡å€¼={df_results[tech].mean():.2f}, æ ‡å‡†å·®={df_results[tech].std():.2f}")


def main():
    """ä¸»å‡½æ•°"""
    # è®¾å¤‡é…ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name()}")

    # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
    print("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    val_dataset = CustomDataset(data_dir)
    val_loader = DataLoader(
        val_dataset,
        batch_size=val_batch_size,
        shuffle=False,
        num_workers=0,  # åœ¨Windowsä¸Šè®¾ç½®ä¸º0
        pin_memory=False  # å½“num_workers=0æ—¶ï¼Œpin_memoryåº”è¯¥ä¸ºFalse
    )

    # åŠ è½½æ¨¡å‹
    print("åŠ è½½æ¨¡å‹...")
    model = load_model(pretrained_weights, num_classes, device)

    # æ‰§è¡Œæ¨ç†
    print("å¼€å§‹æ¨ç†...")
    output_path = os.path.join(output_dir, "competition_tenor.xlsx")
    save_predictions_to_excel(model, val_loader, device, output_path)


if __name__ == "__main__":
    # åœ¨Windowsä¸Šå¿…é¡»ä½¿ç”¨è¿™ä¸ªä¿æŠ¤
    import multiprocessing

    multiprocessing.freeze_support()  # å¯¹äºæ‰“åŒ…æˆexeçš„æƒ…å†µ

    main()
    print("ç¨‹åºæ‰§è¡Œå®Œæ¯•ï¼")